{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BpdJkdBssk9",
    "outputId": "3e9f2d09-032f-4e6f-8113-2ce60b7d13cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA version: 11.0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
    "print(\"CUDA version:\", CUDA_version)\n",
    "\n",
    "if CUDA_version == \"10.0\":\n",
    "    torch_version_suffix = \"+cu100\"\n",
    "elif CUDA_version == \"10.1\":\n",
    "    torch_version_suffix = \"+cu101\"\n",
    "elif CUDA_version == \"10.2\":\n",
    "    torch_version_suffix = \"\"\n",
    "else:\n",
    "    torch_version_suffix = \"+cu110\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1hkDT38hSaP",
    "outputId": "bd4b560b-8c79-4b85-f4c6-c9bee5bf510c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.7.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFxgLV5HAEEw"
   },
   "source": [
    "# Downloading the model\n",
    "\n",
    "CLIP models are distributed as TorchScript modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uLFS29hnhlY4"
   },
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"RN50\": \"https://openaipublic.azureedge.net/clip/models/afeb0e10f9e5a86da6080e35cf09123aca3b358a0c3e3b6c78a7b63bc04b6762/RN50.pt\",\n",
    "    \"RN101\": \"https://openaipublic.azureedge.net/clip/models/8fa8567bab74a42d41c5915025a8e4538c3bdbe8804a470a72f30b0d94fab599/RN101.pt\",\n",
    "    \"RN50x4\": \"https://openaipublic.azureedge.net/clip/models/7e526bd135e493cef0776de27d5f42653e6b4c8bf9e0f653bb11773263205fdd/RN50x4.pt\",\n",
    "    \"ViT-B/32\": \"https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cboKZocQlSYX",
    "outputId": "c68e1686-f0b6-43a5-8006-a3da4c4e1fac"
   },
   "outputs": [],
   "source": [
    "!wget {MODELS[\"ViT-B/32\"]} -O model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(\"model.pt\").cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBRVTY9lbGm8",
    "outputId": "d46ae7c1-aed0-474f-a696-5b015e7aa06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 151,277,313\n",
      "Input resolution: 224\n",
      "Context length: 77\n",
      "Vocab size: 49408\n"
     ]
    }
   ],
   "source": [
    "input_resolution = model.input_resolution.item()\n",
    "context_length = model.context_length.item()\n",
    "vocab_size = model.vocab_size.item()\n",
    "\n",
    "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
    "print(\"Input resolution:\", input_resolution)\n",
    "print(\"Context length:\", context_length)\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21slhZGCqANb"
   },
   "source": [
    "# Image Preprocessing\n",
    "\n",
    "We resize the input images and center-crop them to conform with the image resolution that the model expects. Before doing so, we will normalize the pixel intensity using the dataset mean and standard deviation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "d6cpiIFHp9N6"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "\n",
    "preprocess = Compose([\n",
    "    Resize(input_resolution, interpolation=Image.BICUBIC),\n",
    "    CenterCrop(input_resolution),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "image_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073])\n",
    "image_std = torch.tensor([0.26862954, 0.26130258, 0.27577711])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tMc1AXzBlhzm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_list = ['synthetic', 'natural' ]\n",
    "test_set_list = ['synthetic', \"natural\", \"natural_mirrored\",\n",
    "                 \"NS2\",\n",
    "                \"NS6\", \n",
    "                \"NSd4\",\n",
    "                \"S2\",\n",
    "                \"S6\",\n",
    "                \"Sd4\",\n",
    "                \"flank1S\",\n",
    "                \"flank2S\",\n",
    "                \"flank3S\",\n",
    "                \"flank1NS\",\n",
    "                \"flank2NS\",\n",
    "                \"flank3NS\",\n",
    "                \"stripe2S\",\n",
    "                \"stripe4S\",\n",
    "                \"stripe6S\",\n",
    "                \"stripe8S\",\n",
    "                \"stripe10S\",\n",
    "                \"stripe2NS\",\n",
    "                \"stripe4NS\",\n",
    "                \"stripe6NS\",\n",
    "                \"stripe8NS\",\n",
    "                \"stripe10NS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For RSA activations\n",
    "train_set_list = ['synthetic']\n",
    "\n",
    "test_set_list = [\n",
    "    \"flank1S\",\n",
    "    \"flank2S\",\n",
    "    \"flank3S\",\n",
    "    \"flank1NS\",\n",
    "    \"flank2NS\",\n",
    "    \"flank3NS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in DataLoader(dataset,  shuffle = True, batch_size=100):\n",
    "            features = model.encode_image(images.cuda())\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH + 'symm_' + \"S0\" + '_test.pkl', 'rb') as handle:\n",
    "    test_set = pickle.load(handle)\n",
    "    test_set = [(test_set[0][i], test_set[1][i]) for i in range(len(test_set[0]))]\n",
    "with open(PATH + 'symm_' + \"S0\" + '_test.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_set, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='./symmetry/' # Make sure this path exists in your drive\n",
    "test_name=\"NS0\"\n",
    "with open(PATH + 'symm_' + test_name + '_test.pkl', 'rb') as handle:\n",
    "    test_set = pickle.load(handle)[:500]\n",
    "inputs = torch.tensor(np.stack([preprocess(Image.fromarray(x[0].astype('uint8')).convert(\"RGB\")) for x in test_set]))\n",
    "inputs -= image_mean[:, None, None]\n",
    "inputs /= image_std[:, None, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.IntTensor(np.stack([x[1] for x in test_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flank1S\n",
      "flank2S\n",
      "flank3S\n",
      "flank1NS\n",
      "flank2NS\n",
      "flank3NS\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "PATH='./symmetry/' # Make sure this path exists in your drive\n",
    "features = {}\n",
    "for test_name in test_set_list:\n",
    "    print(test_name)\n",
    "    gc.collect()\n",
    "    with open(PATH + 'symm_' + test_name + '_test.pkl', 'rb') as handle:\n",
    "        test_set = pickle.load(handle)[:500]\n",
    "\n",
    "    inputs = torch.tensor(np.stack([preprocess(Image.fromarray(x[0].astype('uint8')).convert(\"RGB\")) for x in test_set]))\n",
    "    inputs -= image_mean[:, None, None]\n",
    "    inputs /= image_std[:, None, None]\n",
    "    targets = torch.IntTensor(np.stack([x[1] for x in test_set]))\n",
    "    test = TensorDataset(inputs, targets)\n",
    "    test_features, test_labels = get_features(test)\n",
    "    features[test_name] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[\"flank1S\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_name in test_set_list:\n",
    "    with open(\"/om/user/shobhita/data/symmetry/transformer/rsa_activations/\" + test_name + \"_activations.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(features[test_name], handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYViqfqMv7Ws",
    "outputId": "9df2f735-75a1-458d-add8-33f6a6baa341",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH='./symmetry/' # Make sure this path exists in your drive\n",
    "features = {}\n",
    "acc = {}\n",
    "for train_name in train_set_list:\n",
    "    acc[train_name] = {}\n",
    "    \n",
    "    with open(PATH + 'symm_' + train_name + '_training.pkl', 'rb') as handle:\n",
    "        train_set = pickle.load(handle)\n",
    "    \n",
    "    inputs = torch.tensor(np.stack([preprocess(Image.fromarray(x[0].astype('uint8')).convert(\"RGB\"))  for x in train_set]))\n",
    "    inputs -= image_mean[:, None, None]\n",
    "    inputs /= image_std[:, None, None]\n",
    "    targets = torch.IntTensor(np.stack([x[1] for x in train_set]))\n",
    "    train = TensorDataset(inputs, targets)\n",
    "    train_features, train_labels = get_features(train)\n",
    "    \n",
    "    \n",
    "    classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    del inputs\n",
    "    del train\n",
    "    del train_set\n",
    "    del train_features\n",
    "    \n",
    "    for test_name in test_set_list:\n",
    "        with open(PATH + 'symm_' + test_name + '_test.pkl', 'rb') as handle:\n",
    "            test_set = pickle.load(handle)\n",
    "        \n",
    "        inputs = torch.tensor(np.stack([preprocess(Image.fromarray(x[0].astype('uint8')).convert(\"RGB\")) for x in test_set]))\n",
    "        inputs -= image_mean[:, None, None]\n",
    "        inputs /= image_std[:, None, None]\n",
    "        targets = torch.IntTensor(np.stack([x[1] for x in test_set]))\n",
    "        test = TensorDataset(inputs, targets)\n",
    "        test_features, test_labels = get_features(test)\n",
    "        \n",
    "        features[test_name] = test_features\n",
    "\n",
    "        predictions = classifier.predict(test_features)\n",
    "        accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "        print(train_name)\n",
    "        print(test_name)\n",
    "        print(f\"Accuracy = {accuracy:.3f}\")\n",
    "        acc[train_name][test_name] = accuracy\n",
    "        \n",
    "with open('./transformer_accuracy.pkl', 'wb') as handle:\n",
    "    pickle.dump(acc, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic\n",
      "synthetic\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "natural\n",
      "Accuracy = 65.083\n",
      "synthetic\n",
      "natural_mirrored\n",
      "Accuracy = 87.167\n",
      "synthetic\n",
      "NS2\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "NS6\n",
      "Accuracy = 98.200\n",
      "synthetic\n",
      "NSd4\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "S2\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "S6\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "Sd4\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "flank1S\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "flank2S\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "flank3S\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "flank1NS\n",
      "Accuracy = 0.000\n",
      "synthetic\n",
      "flank2NS\n",
      "Accuracy = 14.800\n",
      "synthetic\n",
      "flank3NS\n",
      "Accuracy = 0.500\n",
      "synthetic\n",
      "stripe2S\n",
      "Accuracy = 98.600\n",
      "synthetic\n",
      "stripe4S\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "stripe6S\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "stripe8S\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "stripe10S\n",
      "Accuracy = 100.000\n",
      "synthetic\n",
      "stripe2NS\n",
      "Accuracy = 74.300\n",
      "synthetic\n",
      "stripe4NS\n",
      "Accuracy = 0.400\n",
      "synthetic\n",
      "stripe6NS\n",
      "Accuracy = 17.400\n",
      "synthetic\n",
      "stripe8NS\n",
      "Accuracy = 96.900\n",
      "synthetic\n",
      "stripe10NS\n",
      "Accuracy = 24.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural\n",
      "synthetic\n",
      "Accuracy = 98.800\n",
      "natural\n",
      "natural\n",
      "Accuracy = 93.417\n",
      "natural\n",
      "natural_mirrored\n",
      "Accuracy = 98.583\n",
      "natural\n",
      "NS2\n",
      "Accuracy = 99.400\n",
      "natural\n",
      "NS6\n",
      "Accuracy = 74.900\n",
      "natural\n",
      "NSd4\n",
      "Accuracy = 20.300\n",
      "natural\n",
      "S2\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "S6\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "Sd4\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "flank1S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "flank2S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "flank3S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "flank1NS\n",
      "Accuracy = 0.000\n",
      "natural\n",
      "flank2NS\n",
      "Accuracy = 0.000\n",
      "natural\n",
      "flank3NS\n",
      "Accuracy = 0.000\n",
      "natural\n",
      "stripe2S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "stripe4S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "stripe6S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "stripe8S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "stripe10S\n",
      "Accuracy = 100.000\n",
      "natural\n",
      "stripe2NS\n",
      "Accuracy = 0.000\n",
      "natural\n",
      "stripe4NS\n",
      "Accuracy = 0.000\n",
      "natural\n",
      "stripe6NS\n",
      "Accuracy = 0.000\n",
      "natural\n",
      "stripe8NS\n",
      "Accuracy = 0.000\n",
      "natural\n",
      "stripe10NS\n",
      "Accuracy = 0.000\n"
     ]
    }
   ],
   "source": [
    "PATH='./symmetry/' # Make sure this path exists in your drive\n",
    "\n",
    "acc = {}\n",
    "for train_name in train_set_list:\n",
    "    acc[train_name] = {}\n",
    "    \n",
    "    with open(PATH + 'symm_' + train_name + '_training.pkl', 'rb') as handle:\n",
    "        train_set = pickle.load(handle)\n",
    "    \n",
    "    inputs = torch.tensor(np.stack([preprocess(Image.fromarray(x[0].astype('uint8')).convert(\"RGB\"))  for x in train_set]))\n",
    "    inputs -= image_mean[:, None, None]\n",
    "    inputs /= image_std[:, None, None]\n",
    "    targets = torch.IntTensor(np.stack([x[1] for x in train_set]))\n",
    "    train = TensorDataset(inputs, targets)\n",
    "    train_features, train_labels = get_features(train)\n",
    "    \n",
    "    \n",
    "    classifier = LogisticRegression(random_state=0, C=0.316, max_iter=1000, verbose=1)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    del inputs\n",
    "    del train\n",
    "    del train_set\n",
    "    del train_features\n",
    "    \n",
    "    for test_name in test_set_list:\n",
    "        with open(PATH + 'symm_' + test_name + '_test.pkl', 'rb') as handle:\n",
    "            test_set = pickle.load(handle)\n",
    "        \n",
    "        inputs = torch.tensor(np.stack([preprocess(Image.fromarray(x[0].astype('uint8')).convert(\"RGB\")) for x in test_set]))\n",
    "        inputs -= image_mean[:, None, None]\n",
    "        inputs /= image_std[:, None, None]\n",
    "        targets = torch.IntTensor(np.stack([x[1] for x in test_set]))\n",
    "        test = TensorDataset(inputs, targets)\n",
    "        test_features, test_labels = get_features(test)\n",
    "\n",
    "        predictions = classifier.predict(test_features)\n",
    "        accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "        print(train_name)\n",
    "        print(test_name)\n",
    "        print(f\"Accuracy = {accuracy:.3f}\")\n",
    "        acc[train_name][test_name] = accuracy\n",
    "        \n",
    "with open('./transformer_accuracy.pkl', 'wb') as handle:\n",
    "    pickle.dump(acc, handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [100.0, 1000.0, 10000.0]\n",
    "train_set_list = ['synthetic', 'natural' ]\n",
    "path = \"/om/user/shobhita/src/symmetry/transformers/symmetry/symmetry/\"\n",
    "\n",
    "full_accs = {}\n",
    "for size in train_sizes:\n",
    "    for train_set in train_set_list:\n",
    "        with open(path + \"transformer_accuracy_{}_training_{}.pkl\".format(train_set, size), \"rb\") as handle:\n",
    "            acc = pickle.load(handle)\n",
    "            acc = {key: val for key, val in acc.items()}\n",
    "            full_accs[\"{}_{}\".format(train_set, size)] = acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(full_accs)\n",
    "with open(path + \"full_transformer_accs.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(df, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"full_transformer_accs.pkl\", \"rb\") as handle:\n",
    "    a= pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synthetic_100.0</th>\n",
       "      <th>natural_100.0</th>\n",
       "      <th>synthetic_1000.0</th>\n",
       "      <th>natural_1000.0</th>\n",
       "      <th>synthetic_10000.0</th>\n",
       "      <th>natural_10000.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>synthetic</th>\n",
       "      <td>99.800000</td>\n",
       "      <td>49.300000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>88.100000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <td>58.833333</td>\n",
       "      <td>88.333333</td>\n",
       "      <td>61.25</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>64.583333</td>\n",
       "      <td>93.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural_mirrored</th>\n",
       "      <td>72.666667</td>\n",
       "      <td>95.916667</td>\n",
       "      <td>79.25</td>\n",
       "      <td>98.333333</td>\n",
       "      <td>86.333333</td>\n",
       "      <td>98.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NS2</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>98.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NS6</th>\n",
       "      <td>99.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.30</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>97.800000</td>\n",
       "      <td>63.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NSd4</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S6</th>\n",
       "      <td>99.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sd4</th>\n",
       "      <td>99.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.90</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flank1S</th>\n",
       "      <td>99.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flank2S</th>\n",
       "      <td>99.600000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flank3S</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flank1NS</th>\n",
       "      <td>50.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flank2NS</th>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flank3NS</th>\n",
       "      <td>31.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe2S</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>69.60</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.300000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe4S</th>\n",
       "      <td>96.800000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe6S</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.40</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe8S</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>98.70</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe10S</th>\n",
       "      <td>94.100000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.90</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe2NS</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe4NS</th>\n",
       "      <td>93.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe6NS</th>\n",
       "      <td>99.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe8NS</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripe10NS</th>\n",
       "      <td>90.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.900000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  synthetic_100.0  natural_100.0  synthetic_1000.0  \\\n",
       "synthetic               99.800000      49.300000            100.00   \n",
       "natural                 58.833333      88.333333             61.25   \n",
       "natural_mirrored        72.666667      95.916667             79.25   \n",
       "NS2                    100.000000       0.000000            100.00   \n",
       "NS6                     99.200000       0.000000             98.30   \n",
       "NSd4                   100.000000       0.000000            100.00   \n",
       "S2                     100.000000     100.000000            100.00   \n",
       "S6                      99.800000     100.000000            100.00   \n",
       "Sd4                     99.800000     100.000000             99.90   \n",
       "flank1S                 99.800000     100.000000            100.00   \n",
       "flank2S                 99.600000     100.000000            100.00   \n",
       "flank3S                100.000000     100.000000            100.00   \n",
       "flank1NS                50.600000       0.000000              2.70   \n",
       "flank2NS                94.000000       0.000000             48.80   \n",
       "flank3NS                31.900000       0.000000              4.00   \n",
       "stripe2S                18.700000     100.000000             69.60   \n",
       "stripe4S                96.800000     100.000000            100.00   \n",
       "stripe6S                58.000000     100.000000             97.40   \n",
       "stripe8S                61.000000     100.000000             98.70   \n",
       "stripe10S               94.100000     100.000000             99.90   \n",
       "stripe2NS              100.000000       0.000000             99.30   \n",
       "stripe4NS               93.900000       0.000000             30.00   \n",
       "stripe6NS               99.900000       0.000000             85.60   \n",
       "stripe8NS              100.000000       0.000000            100.00   \n",
       "stripe10NS              90.800000       0.000000             58.70   \n",
       "\n",
       "                  natural_1000.0  synthetic_10000.0  natural_10000.0  \n",
       "synthetic              88.100000         100.000000        97.900000  \n",
       "natural                92.500000          64.583333        93.333333  \n",
       "natural_mirrored       98.333333          86.333333        98.583333  \n",
       "NS2                    89.500000         100.000000        98.800000  \n",
       "NS6                    37.100000          97.800000        63.800000  \n",
       "NSd4                    0.100000         100.000000        13.200000  \n",
       "S2                    100.000000         100.000000       100.000000  \n",
       "S6                    100.000000         100.000000       100.000000  \n",
       "Sd4                   100.000000         100.000000       100.000000  \n",
       "flank1S               100.000000         100.000000       100.000000  \n",
       "flank2S               100.000000         100.000000       100.000000  \n",
       "flank3S               100.000000         100.000000       100.000000  \n",
       "flank1NS                0.000000           0.000000         0.000000  \n",
       "flank2NS                0.000000          18.700000         0.000000  \n",
       "flank3NS                0.000000           0.600000         0.000000  \n",
       "stripe2S              100.000000          97.300000       100.000000  \n",
       "stripe4S              100.000000         100.000000       100.000000  \n",
       "stripe6S              100.000000         100.000000       100.000000  \n",
       "stripe8S              100.000000         100.000000       100.000000  \n",
       "stripe10S             100.000000         100.000000       100.000000  \n",
       "stripe2NS               0.000000          82.600000         0.000000  \n",
       "stripe4NS               0.100000           1.000000         0.000000  \n",
       "stripe6NS               0.000000          30.200000         0.000000  \n",
       "stripe8NS               0.000000          98.200000         0.000000  \n",
       "stripe10NS              0.000000          36.900000         0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Symmetry Interacting with CLIP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "172d6fa74fd645a3ba44023ab4512bfb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d08d0d522f04489955c41338d325bb7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aca3895bea8b4392a141f370c46bee01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d1cd677ced4b4387bcff17763e6ee698": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d2e8df38df6f4611b616043a414c50ee",
       "IPY_MODEL_d69c24836b934022bfa540568d8cead2"
      ],
      "layout": "IPY_MODEL_4d08d0d522f04489955c41338d325bb7"
     }
    },
    "d2e8df38df6f4611b616043a414c50ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_172d6fa74fd645a3ba44023ab4512bfb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aca3895bea8b4392a141f370c46bee01",
      "value": 1
     }
    },
    "d69c24836b934022bfa540568d8cead2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e68ed231b789486fb2dee5a76223075d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ec6b8047740c4ba39fda2215f7c90b34",
      "value": " 169009152/? [00:30&lt;00:00, 17769795.44it/s]"
     }
    },
    "e68ed231b789486fb2dee5a76223075d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec6b8047740c4ba39fda2215f7c90b34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
